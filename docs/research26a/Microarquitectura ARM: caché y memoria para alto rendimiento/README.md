
<div align="center">

#  Microarquitectura ARM  
##  Cach√© y Memoria para Alto Rendimiento
![ARM presenta las microarquitecturas Cortex-A78 ‚Äì Cortex-X1 y GPU Mali-G78 |  MKFET_Labs](https://i0.wp.com/mkfetlabs.com/wp-content/uploads/2021/05/arm.jpg?resize=710%2C210&ssl=1)

</div>

---

#  Introducci√≥n: Por qu√© la memoria define el rendimiento

En procesadores ARM modernos, especialmente desde **ARMv8 en adelante**, el rendimiento real del sistema no est√° determinado principalmente por la capacidad de las unidades aritm√©ticas, sino por la eficiencia del **subsistema de memoria**.

La latencia de acceso a memoria principal es √≥rdenes de magnitud mayor que la latencia de ejecuci√≥n de una instrucci√≥n aritm√©tica simple. Por esta raz√≥n, el dise√±o de:

-  La jerarqu√≠a de cach√©  
-  El modelo de coherencia  
-  El sistema de traducci√≥n de direcciones  

son elementos cr√≠ticos en la microarquitectura.

ARM naci√≥ con un enfoque en **eficiencia energ√©tica**, pero en implementaciones modernas como **Cortex-A** y **Neoverse**, tambi√©n compite en **rendimiento absoluto**. Para aprovechar completamente estos procesadores, el desarrollador debe entender c√≥mo interact√∫a su c√≥digo con la jerarqu√≠a de memoria.

![Â§ßÊ†∏‰∏çÂ§üÂº∫ÔºüARMË∂ÖÂ§ßÊ†∏ÂøÉÂèëÂ∏ÉÔºöIPCÊö¥Ê∂®30%_ÁÉ≠ÁÇπËµÑËÆØ_ÂÆâÂÖîÂÖî](https://img.antutu.com/20200527/20200527092635_67568.png)

---

##  Impacto real de la latencia

| Operaci√≥n | Latencia Aproximada | Orden de Magnitud |
|------------|--------------------|-------------------|
| Suma entera | 1 ciclo | Muy baja |
| Acceso L1 | 3‚Äì4 ciclos | Baja |
| Acceso L2 | 10‚Äì20 ciclos | Media |
| Acceso DRAM | 100+ ciclos | Muy alta |

> üîé Incluso con ejecuci√≥n fuera de orden, el procesador no puede ocultar completamente latencias profundas si el patr√≥n de acceso es impredecible o altamente disperso.

---

#  Jerarqu√≠a de Memoria en ARM

## 2.1 Arquitectura Harvard Modificada

ARM utiliza una arquitectura **Harvard modificada**.

En el nivel L1 existen dos cach√©s separadas:

- üìò L1I ‚Üí Instrucciones  
- üìó L1D ‚Üí Datos  

Esto permite realizar **fetch de instrucciones y acceso a datos en paralelo**, evitando conflictos estructurales.

```mermaid
flowchart TD
    CPU --> L1I[L1 Instruction Cache]
    CPU --> L1D[L1 Data Cache]
    L1I --> L2[L2 Cache Unificada]
    L1D --> L2
    L2 --> L3[L3 Compartida]
    L3 --> DRAM[Memoria Principal]
```

### Organizaci√≥n t√≠pica

- L1: privada por n√∫cleo  
- L2: usualmente privada por n√∫cleo  
- L3: compartida entre m√∫ltiples n√∫cleos  

Esta organizaci√≥n reduce la frecuencia de accesos a memoria principal y mejora la **escalabilidad multi-core**.

---

## 2.2 Latencias relativas y su impacto

```mermaid
graph LR
    L1[L1 ~ 3 ciclos] --> CPU
    L2[L2 ~ 15 ciclos] --> CPU
    DRAM[DRAM ~ 120 ciclos] --> CPU
```

La diferencia de latencia implica que el rendimiento est√° fuertemente condicionado por la **tasa de fallos de cach√©**.

---

#  Dise√±o y Funcionamiento de la Cach√©

---

## 3.1 Tama√±o de l√≠nea y localidad espacial

En ARMv8, el tama√±o t√≠pico de l√≠nea de cach√© es:

>  **64 bytes**

Cuando se accede a una direcci√≥n de memoria, se carga la l√≠nea completa que contiene ese dato.

### Acceso secuencial (eficiente)

```
| A | B | C | D |   ‚Üê misma l√≠nea de 64 bytes
```

### Acceso disperso (ineficiente)

```
| A |       | B |       | C |
(Fallo)     (Fallo)     (Fallo)
```

 Si los datos est√°n contiguos, la l√≠nea cargada contendr√° informaci√≥n que ser√° utilizada en accesos posteriores.

 La **localidad espacial** es uno de los principios m√°s importantes para optimizar en ARM.
![Que es la cach√© y por qu√© ayuda en la carga de tu sitio - PPabloTech](https://ppablotech.cl/wp-content/uploads/2018/11/cache.jpg)

---

## 3.2 Asociatividad y conflictos

Las cach√©s son **asociativas por conjuntos**.

Cada direcci√≥n de memoria puede ubicarse solo en un conjunto espec√≠fico dentro de varias v√≠as posibles.

```mermaid
flowchart TD
    Address[Direcci√≥n] --> Set[Conjunto]
    Set --> Way1[V√≠a 1]
    Set --> Way2[V√≠a 2]
    Set --> Way3[V√≠a 3]
    Set --> Way4[V√≠a 4]
```

‚ö†Ô∏è Si m√∫ltiples direcciones compiten por el mismo conjunto, pueden expulsarse entre s√≠ aunque la cach√© no est√© llena.

Este fen√≥meno puede generar degradaciones de rendimiento dif√≠ciles de detectar.

---

## 3.3 Pol√≠ticas de escritura

La mayor√≠a de implementaciones utilizan:

>  **Write-back + Write-allocate**

| Pol√≠tica | Funcionamiento | Impacto |
|------------|---------------|----------|
| Write-through | Escribe directo en memoria | M√°s tr√°fico |
| Write-back | Modifica primero en cach√© | Menos tr√°fico |
| Write-allocate | Trae l√≠nea al escribir | Mejor promedio |

Este enfoque reduce tr√°fico hacia DRAM, pero aumenta la complejidad del sistema de coherencia.

---

#  Coherencia de Cach√© en Sistemas Multi-Core

---

## 4.1 Protocolos de coherencia

En sistemas multi-core, cada n√∫cleo mantiene su propia cach√© privada.

Para mantener consistencia se emplean protocolos derivados de:

- MESI  
- MOESI  

Implementados mediante interconexiones como:

- AMBA ACE  
- AMBA CHI  

```mermaid
sequenceDiagram
    participant Core1
    participant Core2
    participant Interconnect

    Core1->>Interconnect: Write Line X
    Interconnect->>Core2: Invalidate Line X
    Core2-->>Interconnect: Ack
```

Cuando un n√∫cleo modifica una l√≠nea compartida, se env√≠an **invalidaciones** a otros n√∫cleos.

---

## 4.2 False Sharing

El *false sharing* ocurre cuando dos hilos modifican variables distintas dentro de la misma l√≠nea de 64 bytes.

```
| Var A | Var B | padding |
```

Aunque no est√©n relacionadas, la l√≠nea completa se invalida en cada escritura.

‚ö†Ô∏è Puede reducir dr√°sticamente la escalabilidad.

### ‚úî Soluci√≥n: Alineamiento

```c
struct {
    int varA;
    char padding[60];
};
```

---

#  Modelo de Memoria en ARM

---

## 5.1 Modelo d√©bil y reordenamiento

ARM permite reordenamiento de cargas y almacenamientos cuando no existen dependencias expl√≠citas.

```mermaid
flowchart LR
    StoreA --> StoreB
    LoadX --> LoadY
```

Esto mejora eficiencia del pipeline y paralelismo interno.

‚ö†Ô∏è El orden en el c√≥digo no siempre coincide con el orden observado por otros n√∫cleos.

---

## 5.2 Barreras y sincronizaci√≥n

ARM proporciona instrucciones como:

| Instrucci√≥n | Funci√≥n |
|------------|---------|
| DMB | Data Memory Barrier |
| DSB | Data Synchronization Barrier |
| ISB | Instruction Synchronization Barrier |

En programaci√≥n moderna se usan mediante primitivas at√≥micas con sem√°nticas:

- Acquire  
- Release  

Comprender el modelo d√©bil es esencial para c√≥digo concurrente correcto.

---

#  TLB y Traducci√≥n de Direcciones

---

## 6.1 Funcionamiento del TLB

El TLB almacena traducciones de direcciones virtuales a f√≠sicas.

```mermaid
flowchart TD
    CPU --> TLB
    TLB -->|Hit| MemoriaFisica
    TLB -->|Miss| PageWalk
    PageWalk --> MemoriaFisica
```

Un fallo de TLB implica m√∫ltiples accesos adicionales y puede impactar el rendimiento de forma comparable a un fallo profundo de cach√©.

---

## 6.2 P√°ginas grandes

ARMv8 soporta:

| Tama√±o | Ventaja |
|--------|----------|
| 4KB | Est√°ndar |
| 2MB | Reduce presi√≥n TLB |
| 1GB | Minimiza fallos |

En aplicaciones con grandes regiones contiguas, usar p√°ginas grandes mejora la estabilidad del rendimiento.

---

#  Patrones de Acceso y Dise√±o Orientado a Datos

El rendimiento en ARM depende en gran medida de c√≥mo se organizan los datos en memoria.

## Comparaci√≥n de estructuras

| Dise√±o | Comportamiento |
|--------|---------------|
| Lista enlazada | Muchos fallos de cach√© |
| Arreglo contiguo | Alta localidad |
| Structure of Arrays | M√°xima densidad √∫til |

### Ejemplo disperso

```c
node->next->next->value;
```

### Ejemplo contiguo

```c
for(int i=0;i<N;i++)
    sum += arr[i];
```

El dise√±o orientado a datos propone estructurar la memoria seg√∫n el patr√≥n real de acceso.

Optimizar en ARM implica dise√±ar pensando en la jerarqu√≠a de memoria, no √∫nicamente en la abstracci√≥n l√≥gica del problema.

---

#  Conclusi√≥n

En microarquitectura ARM moderna, el subsistema de memoria es el **factor dominante en el rendimiento**.

Para desarrollar software eficiente es esencial:

- Minimizar fallos de cach√©  
-  Reducir presi√≥n sobre el TLB  
-  Evitar false sharing  
-  Comprender el modelo de memoria d√©bil  
-  Dise√±ar estructuras con alta localidad  

---

<div align="center">

##  Rendimiento = Algoritmo + Organizaci√≥n de Datos + Interacci√≥n con la Memoria

**Dominar la jerarqu√≠a de memoria es dominar el rendimiento en ARM.**

</div>
